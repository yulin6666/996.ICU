{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“cat_dog.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulin6666/996.ICU/blob/master/cat_dog_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9XNh677KzSU3",
        "colab_type": "code",
        "outputId": "8b963320-23d3-455a-a216-fdc58ba38f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, math,cv2\n",
        "import tensorflow as tf\n",
        "from IPython.display import display, Image, HTML\n",
        "\n",
        "# 训练集\n",
        "TRAIN_DIR='./drive/My Drive/Colab Notebooks/cat_dog_data/data/train/'\n",
        "train_images_all = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)]\n",
        "train_images_dog = [i for i in train_images_all if 'dog' in i]\n",
        "train_images_cat = [i for i in train_images_all if 'cat' in i]\n",
        "train_images_filepaths = train_images_dog + train_images_cat\n",
        "TRAIN_DATA_NUM = 2000 # 狗和猫各自的训练图片数量\n",
        "VALIDATION_DATA_NUM = 500 # 狗和猫各自的验证图片数量\n",
        "TEST_NUM = 1000 # 测试集数量\n",
        "TRAIN_NUM = TRAIN_DATA_NUM * 2 # 训练集的图片数量，不包含验证集\n",
        "VALIDATION_NUM = VALIDATION_DATA_NUM * 2 # 验证集的图片数量\n",
        "train_images_filepaths = train_images_filepaths[:TRAIN_NUM+VALIDATION_NUM]\n",
        "train_images_labels = np.array([1] * (TRAIN_DATA_NUM + VALIDATION_DATA_NUM) \\\n",
        "                               + [0] * (TRAIN_DATA_NUM + VALIDATION_DATA_NUM)) # 1表示dog，0表示cat\n",
        "print(\"train num:\",np.array(train_images_filepaths).shape)\n",
        "\n",
        "# 测试集\n",
        "TEST_DIR = './drive/My Drive/Colab Notebooks/cat_dog_data/data/test/'\n",
        "test_images_filepaths = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
        "test_images_filepaths = test_images_filepaths[:TEST_NUM]\n",
        "print(\"test num:\",np.array(test_images_filepaths).shape)\n",
        "\n",
        "#预处理图片\n",
        "def read_image(file_path):\n",
        "    img = cv2.imread(file_path,cv2.IMREAD_COLOR)\n",
        "    if img.shape[0] > img.shape[1]:\n",
        "        img_size = (IMAGE_SIZE, int(round(float(img.shape[1] / img.shape[0]) * IMAGE_SIZE)))\n",
        "    else:\n",
        "        img_size = (int(round(float(img.shape[0] / img.shape[1]) * IMAGE_SIZE)), IMAGE_SIZE)  \n",
        "    tmp_img = cv2.resize(img, (img_size[1], img_size[0]), interpolation=cv2.INTER_CUBIC)\n",
        "    ret_img = cv2.copyMakeBorder(tmp_img, 0, IMAGE_SIZE-img_size[0], 0, IMAGE_SIZE-img_size[1], cv2.BORDER_CONSTANT, 0)\n",
        "    return ret_img[:,:,::-1]\n",
        "    \n",
        "IMAGE_SIZE = 250\n",
        "CHANNELS = 3\n",
        "train_dataset = np.ndarray((TRAIN_NUM + VALIDATION_NUM, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.uint8)\n",
        "for i, image_path in enumerate(train_images_filepaths):\n",
        "    if(i%1000==0):\n",
        "      print(\"processed train image:\",i)\n",
        "    train_dataset[i]=read_image(image_path)\n",
        "print(\"Train shape: {}\".format(train_dataset.shape))\n",
        "\n",
        "# 载入测试集\n",
        "test_dataset = np.ndarray((TEST_NUM, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), dtype=np.uint8)\n",
        "for i, image_path in enumerate(test_images_filepaths):\n",
        "    if(i%1000==0):\n",
        "      print(\"processed test image:\",i)\n",
        "    test_dataset[i] = read_image(image_path)\n",
        "print(\"Test shape:\",test_dataset.shape)\n",
        "\n",
        "#随机打乱数据\n",
        "np.random.seed(201712)\n",
        "def randomize(dataset, labels):\n",
        "    permutation = np.random.permutation(labels.shape[0])\n",
        "    shuffled_dataset = dataset[permutation,:,:,:]\n",
        "    shuffled_labels = labels[permutation]\n",
        "    return shuffled_dataset, shuffled_labels\n",
        "\n",
        "train_dataset_rand, train_labels_rand = randomize(train_dataset,train_images_labels)\n",
        "train = train_dataset_rand[:TRAIN_NUM,:,:,:]\n",
        "train_labels = train_labels_rand[:TRAIN_NUM]\n",
        "valid = train_dataset_rand[-VALIDATION_NUM:]\n",
        "valid_labels = train_labels_rand[-VALIDATION_NUM:]\n",
        "print('Train shape: ', train.shape, train_labels.shape)\n",
        "print('Valid shape: ', valid.shape, valid_labels.shape)\n",
        "\n",
        "\n",
        "#生成字符串型的属性\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "# 生成整数型的属性\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "# 把数据写到多个文件中\n",
        "def save_multiple_tfrecords(images, labels, filename, instances_per_file):\n",
        "    image_num = labels.shape[0]\n",
        "    file_num = math.ceil(image_num / instances_per_file) # 计算需要写的文件总数\n",
        "    \n",
        "    # 遍历每一张图片\n",
        "    write_num = instances_per_file\n",
        "    cur_file_no = -1\n",
        "    for i in range(image_num):\n",
        "        # 如果一个文件的图片达到预定的数目，则创建新的文件继续写\n",
        "        if write_num == instances_per_file:\n",
        "            write_num = 0\n",
        "            cur_file_no += 1\n",
        "            write_filename = filename + '.tfrecords-%.4d-of-%.4d' % (cur_file_no, file_num)\n",
        "            print('Writing ' + write_filename)\n",
        "            writer = tf.python_io.TFRecordWriter(write_filename)\n",
        "        # 写图片到文件\n",
        "        image_bytes = images[i].tostring()\n",
        "        example = tf.train.Example(\n",
        "            features=tf.train.Features(\n",
        "                feature={\n",
        "                    'label': _int64_feature(labels[i]),\n",
        "                    'image_raw': _bytes_feature(image_bytes)\n",
        "            }))\n",
        "        writer.write(example.SerializeToString())\n",
        "        write_num += 1\n",
        "    writer.close()\n",
        "    print('Writing End.')\n",
        "\n",
        "    \n",
        "save_multiple_tfrecords(train, train_labels, './drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/train', 1024)\n",
        "save_multiple_tfrecords(valid, valid_labels, './drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/valid', VALIDATION_NUM)\n",
        "save_multiple_tfrecords(test_dataset, np.array([0] * TEST_NUM), './drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/test', TEST_NUM)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "train num: (5000,)\n",
            "test num: (1000,)\n",
            "processed train image: 0\n",
            "processed train image: 1000\n",
            "processed train image: 2000\n",
            "processed train image: 3000\n",
            "processed train image: 4000\n",
            "Train shape: (5000, 250, 250, 3)\n",
            "processed test image: 0\n",
            "Test shape: (1000, 250, 250, 3)\n",
            "Train shape:  (4000, 250, 250, 3) (4000,)\n",
            "Valid shape:  (1000, 250, 250, 3) (1000,)\n",
            "Writing ./drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/train.tfrecords-0000-of-0004\n",
            "Writing ./drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/train.tfrecords-0001-of-0004\n",
            "Writing ./drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/train.tfrecords-0002-of-0004\n",
            "Writing ./drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/train.tfrecords-0003-of-0004\n",
            "Writing End.\n",
            "Writing ./drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/valid.tfrecords-0000-of-0001\n",
            "Writing End.\n",
            "Writing ./drive/My Drive/Colab Notebooks/cat_dog_data/data/tfrecord/test.tfrecords-0000-of-0001\n",
            "Writing End.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9xyUZYVYzSVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLAjbtkCzSVH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}